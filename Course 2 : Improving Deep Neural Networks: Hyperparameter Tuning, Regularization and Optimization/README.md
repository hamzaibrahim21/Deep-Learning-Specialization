# Course 2
## Neural Networks and Deep Learning

##### The second course of Deep learning specialization, The black box of deep learning will be opened and you will understand the magic of deep learning [Certificate.](https://coursera.org/share/b244684598b4b46d44978c5f21a6aa3f)

This course explains in detail how to train and develop test sets and analyze bias/variance for building deep learning applications. 
It will give a good background on how to tune hyperparameters and gives an introduction to TensorFlow.



## Schedule
## Week 1
**Learning Objectives**

- Give examples of how different types of initializations can lead to different results
- Examine the importance of initialization in complex neural networks
- Explain the difference between train/dev/test sets
- Diagnose the bias and variance issues in your model
- Assess the right time and place for using regularization methods such as dropout or L2 regularization
- Explain Vanishing and Exploding gradients and how to deal with them
- Use gradient checking to verify the accuracy of your backpropagation implementation
- Apply zeros initialization, random initialization, and He initialization
- Apply regularization to a deep learning model
  
## Week 2
**Learning Objectives**
 
- Apply optimization methods such as (Stochastic) Gradient Descent, Momentum, RMSProp and Adam
- Use random minibatches to accelerate convergence and improve optimization
- Describe the benefits of learning rate decay and apply it to your optimization


## Week 3
**Learning Objectives** 

- Master the process of hyperparameter tuning
- Describe softmax classification for multiple classes
- Apply batch normalization to make your neural network more robust
- Build a neural network in TensorFlow and train it on a TensorFlow dataset
- Describe the purpose and operation of GradientTape
- Use tf.Variable to modify the state of a variable
- Apply TensorFlow decorators to speed up code
- Explain the difference between a variable and a constant

